{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SODA Toolchain\n",
    "\n",
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Level Application Input (TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model in TensorFlow (Step 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/giuseppe.sorrentino/SODA/.venv_soda/lib/python3.8/site-packages/voxelmorph/tf/networks.py:124: UserWarning: int_downsize is deprecated, use the int_resolution parameter.\n",
      "  warnings.warn('int_downsize is deprecated, use the int_resolution parameter.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 288, 288, 1)\n",
      "(None, 32, 288, 288, 1)\n",
      "[<KerasTensor: shape=(None, 32, 288, 288, 1) dtype=float32 (created by layer 'vxm_dense_source_input')>, <KerasTensor: shape=(None, 32, 288, 288, 1) dtype=float32 (created by layer 'vxm_dense_target_input')>]\n",
      "[<KerasTensor: shape=(None, 32, 288, 288, 1) dtype=float32 (created by layer 'vxm_dense_transformer')>, <KerasTensor: shape=(None, 16, 144, 144, 3) dtype=float32 (created by layer 'vxm_dense_flow_resize')>]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import numpy as np\n",
    "import voxelmorph as vxm\n",
    "\n",
    "tf.random.set_seed(seed=0)\n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "\n",
    "model_path = \"/home/users/giuseppe.sorrentino/SODA/NonRigidReg/models/abdomreg_intra.h5\"\n",
    "model = vxm.networks.VxmDense.load(\n",
    "    model_path\n",
    ")\n",
    "for input_tensor in model.inputs:\n",
    "    print(input_tensor.shape)\n",
    "\n",
    "print(model.inputs)\n",
    "print(model.outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model to protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/users/giuseppe.sorrentino/SODA/NonRigidReg/soda-opt/docs/tutorials/tensorflow/docker-version/model/simple/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/users/giuseppe.sorrentino/SODA/NonRigidReg/soda-opt/docs/tutorials/tensorflow/docker-version/model/simple/assets\n",
      "2025-04-28 22:23:09.425958: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-04-28 22:23:09.426266: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/users/giuseppe.sorrentino/SODA/NonRigidReg/soda-opt/docs/tutorials/tensorflow/docker-version/output/frozen_graph.pbtxt'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Salva in SavedModel (opzionale, se serve)\n",
    "save_path = os.path.join(os.getcwd(), \"model/simple/\")\n",
    "tf.saved_model.save(model, save_path) \n",
    "\n",
    "@tf.function\n",
    "def infer(moving, fixed):\n",
    "    return model([moving, fixed])\n",
    "\n",
    "inp0, inp1 = model.inputs\n",
    "concrete_func = infer.get_concrete_function(\n",
    "    moving=tf.TensorSpec(shape=inp0.shape, dtype=inp0.dtype, name=inp0.name.split(':')[0]),\n",
    "    fixed =tf.TensorSpec(shape=inp1.shape, dtype=inp1.dtype, name=inp1.name.split(':')[0])\n",
    ")\n",
    "\n",
    "# 5) Congela e salva il grafo\n",
    "frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
    "tf.io.write_graph(\n",
    "    graph_or_graph_def=frozen_func.graph,\n",
    "    logdir=os.getcwd(),\n",
    "    name=\"output/frozen_graph.pbtxt\",\n",
    "    as_text=True\n",
    ")\n",
    "\n",
    "#for op in frozen_func.graph.get_operations():\n",
    "#    print(op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform protobuf into MLIR (Step 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome dell'input: vxm_dense_source_input\n",
      "Nome dell'input: vxm_dense_target_input\n",
      "Nome dell'output: vxm_dense_transformer/map/TensorArrayV2Stack/TensorListStack:0\n",
      "Nome dell'output: vxm_dense_flow_resize/map/TensorArrayV2Stack/TensorListStack:0\n"
     ]
    }
   ],
   "source": [
    "for input_tensor in model.inputs:\n",
    "    print(f\"Nome dell'input: {input_tensor.name} - shape: {input_tensor.shape} - dtype: {input_tensor.dtype}\")\n",
    "\n",
    "for output_tensor in model.outputs:\n",
    "    print(f\"Nome dell'output: {output_tensor.name} - shape: {output_tensor.shape} - dtype: {output_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-28 20:26:09.984063: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/mlir/tensorflow/translate/mlir_roundtrip_flags.cc:109) absl::SimpleAtoi(dim_str, &size) \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t__libc_start_main\n",
      "\t\n",
      "*** End stack trace ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!scripts/protobuf-to-tosa.sh output/frozen_graph.pbtxt output/tosa.mlir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower MLIR to Linalg on Buffers (Step 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/tosa-to-linalg.sh output/tosa.mlir output/linalg-buffers.mlir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SODA-OPT: HW/SW Partitioning and Optimizer (Step 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use soda.launch?\n",
    "\n",
    "### Automatic selection of custom accelerator region\n",
    "\n",
    "Using the pass: `-convert-<abstraction_name>-<operation_name>-to-soda`\n",
    "\n",
    "Such as: `-convert-linalg-generic-to-soda`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual selection of custom accelerator region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the following lines around any code that will become the accelerator:\n",
    "\n",
    "```mlir\n",
    "soda.launch {\n",
    "  // ...\n",
    "  // Code to be transformed into an accelerator\n",
    "  // ...\n",
    "  soda.terminator\n",
    "}\n",
    "```\n",
    "\n",
    "Run next cell and edit [file](output/01searched-edited.mlir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp output/linalg-buffers.mlir output/01searched-edited.mlir\n",
    "\n",
    "# Perform manual edit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **⚠️ <span style=\"color:red;\">IMPORTANT:</span> Please modify the file as described below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the [file](output/01searched-edited.mlir).\n",
    "\n",
    "Modify line 101 to the following lines:\n",
    "\n",
    "```mlir\n",
    "    soda.launch {\n",
    "      linalg.batch_matmul ins(%expand_shape_14, %4 : memref<1x4x8xf32>, memref<1x8x4xf32>) outs(%alloc_16 : memref<1x4x4xf32>)\n",
    "      soda.terminator\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization pipeline\n",
    "\n",
    "![optimizations](imgs/optimization-table.png)\n",
    "\n",
    "### Kernel without SODA-OPT optimizations (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt \\\n",
    "    -soda-outline-bambu-code \\\n",
    "    -soda-extract-arguments-to-xml=using-bare-ptr \\\n",
    "    -soda-generate-bambu-accelcode=no-aa \\\n",
    "    -lower-all-to-llvm=use-bare-ptr-memref-call-conv \\\n",
    "    -mlir-print-ir-after-all \\\n",
    "    output/01searched-edited.mlir \\\n",
    "    -o output/04baseline.mlir \\\n",
    "    2>&1 | cat > output/05intermediate-baseline.mlir\n",
    "\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  mlir-translate -opaque-pointers=0  \\\n",
    "    --mlir-to-llvmir \\\n",
    "    output/04baseline.mlir \\\n",
    "    -o output/05baseline.ll\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [intermediate file](output/05intermediate-baseline.mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel with SODA-OPT optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt \\\n",
    "    -soda-outline-bambu-code \\\n",
    "    -soda-extract-arguments-to-xml=using-bare-ptr \\\n",
    "    -soda-generate-bambu-accelcode \\\n",
    "    -soda-opt-pipeline-for-bambu=use-bare-ptr-memref-call-conv \\\n",
    "    -mlir-print-ir-after-all \\\n",
    "    output/01searched-edited.mlir \\\n",
    "    -o output/04optimized.mlir \\\n",
    "    2>&1 | cat > output/05intermediate-optimized.mlir\n",
    "\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  mlir-translate -opaque-pointers=0  \\\n",
    "    --mlir-to-llvmir \\\n",
    "    output/04optimized.mlir \\\n",
    "    -o output/05optimized.ll\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [intermediate file](output/05intermediate-optimized.mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bambu: Synthesizing the Outlined Kernel (Step 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following configurations are passed to our backend HLS tool:\n",
    "\n",
    "* Target: ASIC generation using the Nangate cell library with the FreePDK 45nm kit\n",
    "* Memory technology: SRAM\n",
    "* Number of memory channels: 2\n",
    "  * Supports 2 parallel reads and 2 parallel writes\n",
    "* Target frequency: 200MHz (5ns period)\n",
    "* Using bambu's floating-point operation support\n",
    "\n",
    "You can change parameters passed to bambu in [scripts/run-bambu.sh](scripts/run-bambu.sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-bambu.sh baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_runtime = \"\"\n",
    "\n",
    "for runtime in open('output/baseline/bambu-log').readlines():\n",
    "    if \"Average execution\" in runtime:\n",
    "        baseline_runtime = [int(s) for s in runtime.split() if s.isdigit()][0]\n",
    "\n",
    "print(\"Average execution in cycles: {}\".format(baseline_runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [Intermediate Dot File](output/baseline/HLS_output/dot/main_kernel/HLS_STGraph.dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-bambu.sh optimized\n",
    "# Takes aprox 30 seconds to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_runtime = \"\"\n",
    "\n",
    "for runtime in open('output/optimized/bambu-log').readlines():\n",
    "    if \"Average execution\" in runtime:\n",
    "        optimized_runtime = [int(s) for s in runtime.split() if s.isdigit()][0]\n",
    "\n",
    "print(\"Average execution in cycles: {}\".format(optimized_runtime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [Intermediate Dot File](output/optimized/HLS_output/dot/main_kernel/HLS_STGraph.dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of runtime results\n",
    "\n",
    "* Display runtime\n",
    "* Display [verilog output file](output/optimized/main_kernel.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average execution in cycles of Baseline kernel:  {}\".format(baseline_runtime))\n",
    "print(\"Average execution in cycles of Optimized kernel: {}\".format(optimized_runtime))\n",
    "print(\"Speedup: {:.1f}\".format(float(baseline_runtime/optimized_runtime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commandline interface\n",
    "\n",
    "To visualize all possible paramenters for our optimization passes run:\n",
    "\n",
    "- `soda-opt -h`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "      --soda-opt-pipeline-for-bambu                    \n",
    "        --affine-tile-size=<ulong>                     \n",
    "        --bitwidth-of-index-type=<uint>                \n",
    "        --max-alloc-size-in-bytes=<uint>               \n",
    "        --max-rank-of-allocated-memref=<uint>          \n",
    "        --number-of-full-unrolls=<uint>                \n",
    "        --permutation-map=<uint>                       \n",
    "        --use-bare-ptr-memref-call-conv                \n",
    "        --no-alloca-promotion                          \n",
    "        --no-buffer-trick                              \n",
    "        --no-scalar-replacement                        \n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt -h 2>&1 | cat > output/helpfile\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open [help file](output/helpfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the number of unrolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt \\\n",
    "    -soda-outline-bambu-code \\\n",
    "    -soda-extract-arguments-to-xml=using-bare-ptr \\\n",
    "    -soda-generate-bambu-accelcode \\\n",
    "    -soda-opt-pipeline-for-bambu=\"use-bare-ptr-memref-call-conv number-of-full-unrolls=1\" \\\n",
    "    -mlir-print-ir-after-all \\\n",
    "    output/01searched-edited.mlir \\\n",
    "    -o output/04optimized.mlir \\\n",
    "    2>&1 | cat > output/05intermediate-optimized.mlir\n",
    "\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  mlir-translate -opaque-pointers=0  \\\n",
    "    --mlir-to-llvmir \\\n",
    "    output/04optimized.mlir \\\n",
    "    -o output/05optimized.ll\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [intermediate file](output/05intermediate-optimized.mlir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-bambu.sh optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default optimization pipeline (again)\n",
    "\n",
    "Three full unrolls of the inner loop yield better latency for this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt \\\n",
    "    -soda-outline-bambu-code \\\n",
    "    -soda-extract-arguments-to-xml=using-bare-ptr \\\n",
    "    -soda-generate-bambu-accelcode \\\n",
    "    -soda-opt-pipeline-for-bambu=use-bare-ptr-memref-call-conv \\\n",
    "    -mlir-print-ir-after-all \\\n",
    "    output/01searched-edited.mlir \\\n",
    "    -o output/04optimized.mlir \\\n",
    "    2>&1 | cat > output/05intermediate-optimized.mlir\n",
    "\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  mlir-translate -opaque-pointers=0  \\\n",
    "    --mlir-to-llvmir \\\n",
    "    output/04optimized.mlir \\\n",
    "    -o output/05optimized.ll\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-bambu.sh optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenRoad Flow: Automatic ASIC place and route (Step 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-openroad.sh baseline\n",
    "\n",
    "# Approx. 4min to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-openroad.sh optimized\n",
    "\n",
    "# Approx. 23min to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of synthesis results\n",
    "\n",
    "* Display area\n",
    "* Display power\n",
    "* Calculate and display FLOPS/W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path_suffix='HLS_output/Synthesis/bash_flow/openroad/logs/nangate45/main_kernel/base/6_report.log'\n",
    "gds_path_suffix='HLS_output/Synthesis/bash_flow/openroad/results/nangate45/main_kernel/base/6_final.gds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_log='output/baseline/'+log_path_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_multiplier = 1 # Open road reports power in W\n",
    "\n",
    "log_file=baseline_log\n",
    "total_power = ()\n",
    "\n",
    "for l in open(log_file, 'r').readlines():\n",
    "  if (\"Total\" in l and \"Group\" not in l):\n",
    "    total_power=float(l.split()[4])*power_multiplier\n",
    "\n",
    "  if (\"Design area\" in l):\n",
    "    available_area=float(l.split()[2])\n",
    "    utilization_area=float(l.split()[4].strip('%'))\n",
    "  \n",
    "\n",
    "print('Baseline accelerator:')\n",
    "print('  total power consumption: {}W'.format(total_power))\n",
    "print('  available chip area: {} um^2'.format(available_area))\n",
    "print('  utilized chip area: {}%'.format(utilization_area))\n",
    "\n",
    "\n",
    "baseline_total_power=total_power\n",
    "baseline_available_area=available_area\n",
    "baseline_utilization_area=utilization_area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized for runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_log='output/optimized/'+log_path_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file=optimized_log\n",
    "total_power = ()\n",
    "\n",
    "for l in open(log_file, 'r').readlines():\n",
    "  if (\"Total\" in l and \"Group\" not in l):\n",
    "    total_power=float(l.split()[4])*power_multiplier\n",
    "\n",
    "  if (\"Design area\" in l):\n",
    "    available_area=float(l.split()[2])\n",
    "    utilization_area=float(l.split()[4].strip('%'))\n",
    "  \n",
    "\n",
    "print('Optimized accelerator:')\n",
    "print('  total power consumption: {}W'.format(total_power))\n",
    "print('  available chip area: {} um^2'.format(available_area))\n",
    "print('  utilized chip area: {}%'.format(utilization_area))\n",
    "\n",
    "optimized_total_power=total_power\n",
    "optimized_available_area=available_area\n",
    "optimized_utilization_area=utilization_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post place and route comparison\n",
    "\n",
    "Considering a matrix multiply kernel has approximatelly 2xNxMxK arithmetic operations\n",
    "\n",
    "And our selected kernel has the following sizes: \n",
    "\n",
    "```mlir\n",
    "linalg.batch_matmul ins(%A, %B : memref<1x4x8xf32>, memref<1x8x4xf32>) \n",
    "                    outs(%C : memref<1x4x4xf32>)\n",
    "\n",
    "```\n",
    "M=4, K=8, N=4\n",
    "\n",
    "We have approximatelly **256** floating point aritihmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giga_multiplier=1e9\n",
    "flop_count = 256 # arithmetic float point operations\n",
    "target_frequency = 200e+6 # 200MHz\n",
    "\n",
    "optimized_runtime_in_s = optimized_runtime/target_frequency\n",
    "baseline_runtime_in_s = baseline_runtime/target_frequency \n",
    "\n",
    "baseline_flops_per_watt= flop_count/baseline_runtime_in_s/baseline_total_power\n",
    "optimized_flops_per_watt= flop_count/optimized_runtime_in_s/optimized_total_power\n",
    "\n",
    "\n",
    "print(\"Execution in cycles of Baseline kernel:  {}\".format(baseline_runtime))\n",
    "print(\"Execution in cycles of Optimized kernel:   {}\".format(optimized_runtime))\n",
    "\n",
    "print(\"Speedup: \\t\\t\\t{:.2f}x\".format(baseline_runtime/optimized_runtime))\n",
    "print(\"Area utilization overhead: \\t {:.2f}x\".format(optimized_utilization_area/baseline_utilization_area))\n",
    "print(\"Area overhead: \\t\\t\\t {:.2f}x\".format(optimized_available_area/baseline_available_area))\n",
    "print(\"Power overhead: \\t\\t {:.2f}x\".format(optimized_total_power/baseline_total_power))\n",
    "\n",
    "print(\"Baseline  \\t\\t\\t {:.2f} GFLOPS/W \".format(baseline_flops_per_watt/giga_multiplier))\n",
    "print(\"Optimized \\t\\t\\t{:.2f} GFLOPS/W\".format(optimized_flops_per_watt/giga_multiplier))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated GDSII files\n",
    "\n",
    "Output files can be found here:\n",
    "\n",
    "* output/baseline/HLS_output/Synthesis/bash_flow/openroad/results/nangate45/main_kernel/base/6_final.gds\n",
    "* output/optimized/HLS_output/Synthesis/bash_flow/openroad/results/nangate45/main_kernel/base/6_final.gds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline and Optimized Side by Side\n",
    "\n",
    "![Side-By-Size](imgs/gds-side-by-side.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93c7c3955e7e5d34b1892eb3eed2f106b954557791a7d399a089a63ede089a6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
