{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SODA Toolchain\n",
    "\n",
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Level Application Input (TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model in TensorFlow (Step 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsorrentino/NonRigidReg/.venv_soda/lib/python3.8/site-packages/voxelmorph/tf/networks.py:124: UserWarning: int_downsize is deprecated, use the int_resolution parameter.\n",
      "  warnings.warn('int_downsize is deprecated, use the int_resolution parameter.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import numpy as np\n",
    "import voxelmorph as vxm\n",
    "\n",
    "tf.random.set_seed(seed=0)\n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "\n",
    "model_path = \"/home/gsorrentino/NonRigidReg/models/abdomreg_intra.h5\"\n",
    "model = vxm.networks.VxmDense.load(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsorrentino/NonRigidReg/.venv_soda/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VoxelmorphMinimalFlatten\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " moving (InputLayer)         [(None, 128, 128, 128, 1)]   0         []                            \n",
      "                                                                                                  \n",
      " fixed (InputLayer)          [(None, 128, 128, 128, 1)]   0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 128, 128, 128, 2)     0         ['moving[0][0]',              \n",
      "                                                                     'fixed[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)             (None, 128, 128, 128, 16)    880       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 128, 128, 128, 16)    0         ['conv3d[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)           (None, 128, 128, 128, 16)    6928      ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 128, 128, 128, 16)    0         ['conv3d_1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3  (None, 64, 64, 64, 16)       0         ['activation_1[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)           (None, 64, 64, 64, 32)       13856     ['max_pooling3d[0][0]']       \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 64, 64, 64, 32)       0         ['conv3d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)           (None, 64, 64, 64, 32)       27680     ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 64, 64, 64, 32)       0         ['conv3d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPoolin  (None, 32, 32, 32, 32)       0         ['activation_3[0][0]']        \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)           (None, 32, 32, 32, 32)       27680     ['max_pooling3d_1[0][0]']     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 32, 32, 32, 32)       0         ['conv3d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)           (None, 32, 32, 32, 32)       27680     ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 32, 32, 32, 32)       0         ['conv3d_5[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPoolin  (None, 16, 16, 16, 32)       0         ['activation_5[0][0]']        \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)           (None, 16, 16, 16, 32)       27680     ['max_pooling3d_2[0][0]']     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 16, 16, 16, 32)       0         ['conv3d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)           (None, 16, 16, 16, 32)       27680     ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 16, 16, 16, 32)       0         ['conv3d_7[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling3d_3 (MaxPoolin  (None, 8, 8, 8, 32)          0         ['activation_7[0][0]']        \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)           (None, 8, 8, 8, 64)          55360     ['max_pooling3d_3[0][0]']     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 8, 8, 8, 64)          0         ['conv3d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)           (None, 8, 8, 8, 64)          110656    ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 8, 8, 8, 64)          0         ['conv3d_9[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling3d (UpSampling3  (None, 16, 16, 16, 64)       0         ['activation_9[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 16, 16, 16, 96)       0         ['up_sampling3d[0][0]',       \n",
      " )                                                                   'activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)          (None, 16, 16, 16, 32)       82976     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 16, 16, 16, 32)       0         ['conv3d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)          (None, 16, 16, 16, 32)       27680     ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 16, 16, 16, 32)       0         ['conv3d_11[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling3d_1 (UpSamplin  (None, 32, 32, 32, 32)       0         ['activation_11[0][0]']       \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 32, 32, 32, 64)       0         ['up_sampling3d_1[0][0]',     \n",
      " )                                                                   'activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)          (None, 32, 32, 32, 32)       55328     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 32, 32, 32, 32)       0         ['conv3d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)          (None, 32, 32, 32, 32)       27680     ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 32, 32, 32, 32)       0         ['conv3d_13[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling3d_2 (UpSamplin  (None, 64, 64, 64, 32)       0         ['activation_13[0][0]']       \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 64, 64, 64, 64)       0         ['up_sampling3d_2[0][0]',     \n",
      " )                                                                   'activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)          (None, 64, 64, 64, 32)       55328     ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 64, 64, 64, 32)       0         ['conv3d_14[0][0]']           \n",
      "                                                                                                  \n",
      " conv3d_15 (Conv3D)          (None, 64, 64, 64, 32)       27680     ['activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 64, 64, 64, 32)       0         ['conv3d_15[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling3d_3 (UpSamplin  (None, 128, 128, 128, 32)    0         ['activation_15[0][0]']       \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 128, 128, 128, 48)    0         ['up_sampling3d_3[0][0]',     \n",
      " )                                                                   'activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_16 (Conv3D)          (None, 128, 128, 128, 32)    41504     ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 128, 128, 128, 32)    0         ['conv3d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv3d_17 (Conv3D)          (None, 128, 128, 128, 32)    27680     ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 128, 128, 128, 32)    0         ['conv3d_17[0][0]']           \n",
      "                                                                                                  \n",
      " flow (Conv3D)               (None, 128, 128, 128, 3)     2595      ['activation_17[0][0]']       \n",
      "                                                                                                  \n",
      " moved (SpatialTransformer)  (None, 128, 128, 128, 1)     0         ['moving[0][0]',              \n",
      "                                                                     'flow[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 674531 (2.57 MB)\n",
      "Trainable params: 674531 (2.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "class SpatialTransformer(layers.Layer):\n",
    "    \"\"\"3D Spatial Transformer using batched 2D warps and static shape enforcement.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        vol, flow = inputs  # vol: [B,D,H,W,C], flow: [B,D,H,W,3]\n",
    "\n",
    "        # 1. Enforce static (non-zero) shapes to satisfy TOSA requirements\n",
    "        #    (TOSA dialect expects all dims ≥ 1 and statically known) \n",
    "        vol  = tf.ensure_shape(vol,  [None, vol.shape[1], vol.shape[2], vol.shape[3], vol.shape[4]])\n",
    "        flow = tf.ensure_shape(flow, [None, flow.shape[1], flow.shape[2], flow.shape[3], 3])          \n",
    "\n",
    "        # 2. Flatten depth dimension into batch: [B,D,H,W,C] → [B*D,H,W,C]\n",
    "        shape = tf.shape(vol)\n",
    "        B, D, H, W, C = shape[0], shape[1], shape[2], shape[3], vol.shape[4]\n",
    "        vol_flat  = tf.reshape(vol,  tf.stack([B * D, H, W, C]))                                     \n",
    "        flow_flat = tf.reshape(flow, tf.stack([B * D, H, W, C]))                                     \n",
    "\n",
    "        # 3. Perform a single batched 2D warp via dense_image_warp,\n",
    "        #    avoiding tf.map_fn loops entirely \n",
    "        moved_flat = tfa.image.dense_image_warp(vol_flat, flow_flat[..., :2])\n",
    "\n",
    "        # 4. Restore original shape: [B*D,H,W,C] → [B,D,H,W,C]\n",
    "        moved = tf.reshape(moved_flat, tf.stack([B, D, H, W, C]))                                     \n",
    "        return moved\n",
    "\n",
    "def conv_block(x, filters, convs=2, kernel_size=3, activation='relu'):\n",
    "    for _ in range(convs):\n",
    "        x = layers.Conv3D(filters, kernel_size, padding='same',\n",
    "                          kernel_initializer='he_normal')(x)\n",
    "        x = layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def build_minimal_voxelmorph(inshape,\n",
    "                             enc_features=(16, 32, 32, 32),\n",
    "                             dec_features=(32, 32, 32, 32, 32, 16, 16)):\n",
    "    moving = layers.Input(shape=(*inshape, 1), name='moving')\n",
    "    fixed  = layers.Input(shape=(*inshape, 1), name='fixed')\n",
    "    x = layers.Concatenate(axis=-1)([moving, fixed])\n",
    "\n",
    "    skips = []\n",
    "    for f in enc_features:\n",
    "        x = conv_block(x, f)\n",
    "        skips.append(x)\n",
    "        x = layers.MaxPool3D(2)(x)\n",
    "\n",
    "    x = conv_block(x, enc_features[-1] * 2)\n",
    "\n",
    "    for f, skip in zip(dec_features, reversed(skips)):\n",
    "        x = layers.UpSampling3D(2)(x)\n",
    "        x = layers.Concatenate(axis=-1)([x, skip])\n",
    "        x = conv_block(x, f)\n",
    "\n",
    "    flow  = layers.Conv3D(3, 3, padding='same', name='flow')(x)\n",
    "    moved = SpatialTransformer(name='moved')([moving, flow])\n",
    "\n",
    "    return models.Model(inputs=[moving, fixed],\n",
    "                        outputs=[moved, flow],\n",
    "                        name='VoxelmorphMinimalFlatten')\n",
    "\n",
    "# Instantiate model for a 128³ volume                        \n",
    "model = build_minimal_voxelmorph((128, 128, 128))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model to protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salva come onnx\n",
    "def save_model_as_onnx(model, output_path):\n",
    "    # Convert the model to a concrete function\n",
    "    full_model = tf.function(lambda x: model(x))\n",
    "    full_model = full_model.get_concrete_function(\n",
    "        [tf.TensorSpec(shape=[None, 128, 128, 128, 1], dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=[None, 128, 128, 128, 1], dtype=tf.float32)]\n",
    "    )\n",
    "\n",
    "    # Convert to a frozen graph\n",
    "    frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "    frozen_func.graph.as_graph_def()\n",
    "\n",
    "    # Save the model as ONNX\n",
    "    tf.saved_model.save(model, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/gsorrentino/NonRigidReg/soda-opt/docs/tutorials/tensorflow/docker-version/model/simple/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/gsorrentino/NonRigidReg/soda-opt/docs/tutorials/tensorflow/docker-version/model/simple/assets\n",
      "2025-05-06 16:53:23.128842: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-05-06 16:53:23.129097: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/gsorrentino/NonRigidReg/soda-opt/docs/tutorials/tensorflow/docker-version/output/frozen_graph.pbtxt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "# 2) Salva in SavedModel (opzionale, se serve)\n",
    "save_path = os.path.join(os.getcwd(), \"model/simple/\")\n",
    "tf.saved_model.save(model, save_path) \n",
    "\n",
    "# 3) Definisci la tf.function con due input\n",
    "@tf.function\n",
    "def infer(moving, fixed):\n",
    "    return model([moving, fixed])\n",
    "\n",
    "# 4) Crea il ConcreteFunction con TensorSpec per entrambi gli input\n",
    "inp0, inp1 = model.inputs\n",
    "\n",
    "concrete_func = infer.get_concrete_function(\n",
    "    moving=tf.TensorSpec(shape=inp0.shape, dtype=inp0.dtype, name=inp0.name.split(':')[0]),\n",
    "    fixed =tf.TensorSpec(shape=inp1.shape, dtype=inp1.dtype, name=inp1.name.split(':')[0])\n",
    ")\n",
    "\n",
    "# 5) Congela e salva il grafo\n",
    "frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
    "tf.io.write_graph(\n",
    "    graph_or_graph_def=frozen_func.graph,\n",
    "    logdir=os.getcwd(),\n",
    "    name=\"output/frozen_graph.pbtxt\",\n",
    "    as_text=True\n",
    ")\n",
    "\n",
    "# printa le informazioni del frozen graph\n",
    "#print(\"Frozen graph:\")\n",
    "#print frozen graph\n",
    "#with tf.io.gfile.GFile(\"output/frozen_graph.pbtxt\", \"r\") as f:\n",
    "#    frozen_graph = f.read()\n",
    "#    print(frozen_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen graph input nodes:\n",
      "moving:0\n",
      "<dtype: 'float32'>\n",
      "(None, 128, 128, 128, 1)\n",
      "fixed:0\n",
      "<dtype: 'float32'>\n",
      "(None, 128, 128, 128, 1)\n",
      "Identity:0\n",
      "<dtype: 'float32'>\n",
      "(None, 128, 128, 128, 1)\n",
      "Identity_1:0\n",
      "<dtype: 'float32'>\n",
      "(None, 128, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# stampa i nomi dei nodi di input nel frozengraph\n",
    "print(\"Frozen graph input nodes:\")\n",
    "for node in frozen_func.inputs:\n",
    "    print(node.name)\n",
    "    print(node.dtype)\n",
    "    print(node.shape)\n",
    "\n",
    "for node in frozen_func.outputs:\n",
    "    print(node.name)\n",
    "    print(node.dtype)\n",
    "    print(node.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform protobuf into MLIR (Step 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 16:53:54.010000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!scripts/protobuf-to-tosa_modified.sh output/frozen_graph.pbtxt output/tosa.mlir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower MLIR to Linalg on Buffers (Step 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/tosa.mlir:46:25: error: operation being parsed with an unregistered dialect. If this is intended, please use -allow-unregistered-dialect with the MLIR tool used\n",
      "    %43 = \"tf.MaxPool3D\"(%42) {data_format = \"NDHWC\", device = \"\", ksize = [1, 2, 2, 2, 1], padding = \"VALID\", strides = [1, 2, 2, 2, 1]} : (tensor<1x128x128x128x16xf32>) -> tensor<1x64x64x64x16xf32>\n",
      "                        ^\n"
     ]
    }
   ],
   "source": [
    "!scripts/tosa-to-linalg.sh output/tosa.mlir output/linalg-buffers.mlir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SODA-OPT: HW/SW Partitioning and Optimizer (Step 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use soda.launch?\n",
    "\n",
    "### Automatic selection of custom accelerator region\n",
    "\n",
    "Using the pass: `-convert-<abstraction_name>-<operation_name>-to-soda`\n",
    "\n",
    "Such as: `-convert-linalg-generic-to-soda`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual selection of custom accelerator region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the following lines around any code that will become the accelerator:\n",
    "\n",
    "```mlir\n",
    "soda.launch {\n",
    "  // ...\n",
    "  // Code to be transformed into an accelerator\n",
    "  // ...\n",
    "  soda.terminator\n",
    "}\n",
    "```\n",
    "\n",
    "Run next cell and edit [file](output/01searched-edited.mlir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp output/linalg-buffers.mlir output/01searched-edited.mlir\n",
    "\n",
    "# Perform manual edit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **⚠️ <span style=\"color:red;\">IMPORTANT:</span> Please modify the file as described below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the [file](output/01searched-edited.mlir).\n",
    "\n",
    "Modify line 101 to the following lines:\n",
    "\n",
    "```mlir\n",
    "    soda.launch {\n",
    "      linalg.batch_matmul ins(%expand_shape_14, %4 : memref<1x4x8xf32>, memref<1x8x4xf32>) outs(%alloc_16 : memref<1x4x4xf32>)\n",
    "      soda.terminator\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization pipeline\n",
    "\n",
    "![optimizations](imgs/optimization-table.png)\n",
    "\n",
    "### Kernel without SODA-OPT optimizations (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt \\\n",
    "    -soda-outline-bambu-code \\\n",
    "    -soda-extract-arguments-to-xml=using-bare-ptr \\\n",
    "    -soda-generate-bambu-accelcode=no-aa \\\n",
    "    -lower-all-to-llvm=use-bare-ptr-memref-call-conv \\\n",
    "    -mlir-print-ir-after-all \\\n",
    "    output/01searched-edited.mlir \\\n",
    "    -o output/04baseline.mlir \\\n",
    "    2>&1 | cat > output/05intermediate-baseline.mlir\n",
    "\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  mlir-translate -opaque-pointers=0  \\\n",
    "    --mlir-to-llvmir \\\n",
    "    output/04baseline.mlir \\\n",
    "    -o output/05baseline.ll\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [intermediate file](output/05intermediate-baseline.mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel with SODA-OPT optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt \\\n",
    "    -soda-outline-bambu-code \\\n",
    "    -soda-extract-arguments-to-xml=using-bare-ptr \\\n",
    "    -soda-generate-bambu-accelcode \\\n",
    "    -soda-opt-pipeline-for-bambu=use-bare-ptr-memref-call-conv \\\n",
    "    -mlir-print-ir-after-all \\\n",
    "    output/01searched-edited.mlir \\\n",
    "    -o output/04optimized.mlir \\\n",
    "    2>&1 | cat > output/05intermediate-optimized.mlir\n",
    "\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  mlir-translate -opaque-pointers=0  \\\n",
    "    --mlir-to-llvmir \\\n",
    "    output/04optimized.mlir \\\n",
    "    -o output/05optimized.ll\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [intermediate file](output/05intermediate-optimized.mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bambu: Synthesizing the Outlined Kernel (Step 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following configurations are passed to our backend HLS tool:\n",
    "\n",
    "* Target: ASIC generation using the Nangate cell library with the FreePDK 45nm kit\n",
    "* Memory technology: SRAM\n",
    "* Number of memory channels: 2\n",
    "  * Supports 2 parallel reads and 2 parallel writes\n",
    "* Target frequency: 200MHz (5ns period)\n",
    "* Using bambu's floating-point operation support\n",
    "\n",
    "You can change parameters passed to bambu in [scripts/run-bambu.sh](scripts/run-bambu.sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-bambu.sh baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_runtime = \"\"\n",
    "\n",
    "for runtime in open('output/baseline/bambu-log').readlines():\n",
    "    if \"Average execution\" in runtime:\n",
    "        baseline_runtime = [int(s) for s in runtime.split() if s.isdigit()][0]\n",
    "\n",
    "print(\"Average execution in cycles: {}\".format(baseline_runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [Intermediate Dot File](output/baseline/HLS_output/dot/main_kernel/HLS_STGraph.dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-bambu.sh optimized\n",
    "# Takes aprox 30 seconds to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_runtime = \"\"\n",
    "\n",
    "for runtime in open('output/optimized/bambu-log').readlines():\n",
    "    if \"Average execution\" in runtime:\n",
    "        optimized_runtime = [int(s) for s in runtime.split() if s.isdigit()][0]\n",
    "\n",
    "print(\"Average execution in cycles: {}\".format(optimized_runtime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [Intermediate Dot File](output/optimized/HLS_output/dot/main_kernel/HLS_STGraph.dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of runtime results\n",
    "\n",
    "* Display runtime\n",
    "* Display [verilog output file](output/optimized/main_kernel.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average execution in cycles of Baseline kernel:  {}\".format(baseline_runtime))\n",
    "print(\"Average execution in cycles of Optimized kernel: {}\".format(optimized_runtime))\n",
    "print(\"Speedup: {:.1f}\".format(float(baseline_runtime/optimized_runtime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commandline interface\n",
    "\n",
    "To visualize all possible paramenters for our optimization passes run:\n",
    "\n",
    "- `soda-opt -h`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "      --soda-opt-pipeline-for-bambu                    \n",
    "        --affine-tile-size=<ulong>                     \n",
    "        --bitwidth-of-index-type=<uint>                \n",
    "        --max-alloc-size-in-bytes=<uint>               \n",
    "        --max-rank-of-allocated-memref=<uint>          \n",
    "        --number-of-full-unrolls=<uint>                \n",
    "        --permutation-map=<uint>                       \n",
    "        --use-bare-ptr-memref-call-conv                \n",
    "        --no-alloca-promotion                          \n",
    "        --no-buffer-trick                              \n",
    "        --no-scalar-replacement                        \n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt -h 2>&1 | cat > output/helpfile\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open [help file](output/helpfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the number of unrolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt \\\n",
    "    -soda-outline-bambu-code \\\n",
    "    -soda-extract-arguments-to-xml=using-bare-ptr \\\n",
    "    -soda-generate-bambu-accelcode \\\n",
    "    -soda-opt-pipeline-for-bambu=\"use-bare-ptr-memref-call-conv number-of-full-unrolls=1\" \\\n",
    "    -mlir-print-ir-after-all \\\n",
    "    output/01searched-edited.mlir \\\n",
    "    -o output/04optimized.mlir \\\n",
    "    2>&1 | cat > output/05intermediate-optimized.mlir\n",
    "\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  mlir-translate -opaque-pointers=0  \\\n",
    "    --mlir-to-llvmir \\\n",
    "    output/04optimized.mlir \\\n",
    "    -o output/05optimized.ll\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize [intermediate file](output/05intermediate-optimized.mlir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-bambu.sh optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default optimization pipeline (again)\n",
    "\n",
    "Three full unrolls of the inner loop yield better latency for this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  soda-opt \\\n",
    "    -soda-outline-bambu-code \\\n",
    "    -soda-extract-arguments-to-xml=using-bare-ptr \\\n",
    "    -soda-generate-bambu-accelcode \\\n",
    "    -soda-opt-pipeline-for-bambu=use-bare-ptr-memref-call-conv \\\n",
    "    -mlir-print-ir-after-all \\\n",
    "    output/01searched-edited.mlir \\\n",
    "    -o output/04optimized.mlir \\\n",
    "    2>&1 | cat > output/05intermediate-optimized.mlir\n",
    "\n",
    "  docker run -u $(id -u) -v $(pwd):/working_dir --rm agostini01/soda \\\n",
    "  mlir-translate -opaque-pointers=0  \\\n",
    "    --mlir-to-llvmir \\\n",
    "    output/04optimized.mlir \\\n",
    "    -o output/05optimized.ll\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-bambu.sh optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tutorial-flow](imgs/flow-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenRoad Flow: Automatic ASIC place and route (Step 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-openroad.sh baseline\n",
    "\n",
    "# Approx. 4min to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! scripts/run-openroad.sh optimized\n",
    "\n",
    "# Approx. 23min to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of synthesis results\n",
    "\n",
    "* Display area\n",
    "* Display power\n",
    "* Calculate and display FLOPS/W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path_suffix='HLS_output/Synthesis/bash_flow/openroad/logs/nangate45/main_kernel/base/6_report.log'\n",
    "gds_path_suffix='HLS_output/Synthesis/bash_flow/openroad/results/nangate45/main_kernel/base/6_final.gds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_log='output/baseline/'+log_path_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_multiplier = 1 # Open road reports power in W\n",
    "\n",
    "log_file=baseline_log\n",
    "total_power = ()\n",
    "\n",
    "for l in open(log_file, 'r').readlines():\n",
    "  if (\"Total\" in l and \"Group\" not in l):\n",
    "    total_power=float(l.split()[4])*power_multiplier\n",
    "\n",
    "  if (\"Design area\" in l):\n",
    "    available_area=float(l.split()[2])\n",
    "    utilization_area=float(l.split()[4].strip('%'))\n",
    "  \n",
    "\n",
    "print('Baseline accelerator:')\n",
    "print('  total power consumption: {}W'.format(total_power))\n",
    "print('  available chip area: {} um^2'.format(available_area))\n",
    "print('  utilized chip area: {}%'.format(utilization_area))\n",
    "\n",
    "\n",
    "baseline_total_power=total_power\n",
    "baseline_available_area=available_area\n",
    "baseline_utilization_area=utilization_area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized for runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_log='output/optimized/'+log_path_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file=optimized_log\n",
    "total_power = ()\n",
    "\n",
    "for l in open(log_file, 'r').readlines():\n",
    "  if (\"Total\" in l and \"Group\" not in l):\n",
    "    total_power=float(l.split()[4])*power_multiplier\n",
    "\n",
    "  if (\"Design area\" in l):\n",
    "    available_area=float(l.split()[2])\n",
    "    utilization_area=float(l.split()[4].strip('%'))\n",
    "  \n",
    "\n",
    "print('Optimized accelerator:')\n",
    "print('  total power consumption: {}W'.format(total_power))\n",
    "print('  available chip area: {} um^2'.format(available_area))\n",
    "print('  utilized chip area: {}%'.format(utilization_area))\n",
    "\n",
    "optimized_total_power=total_power\n",
    "optimized_available_area=available_area\n",
    "optimized_utilization_area=utilization_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post place and route comparison\n",
    "\n",
    "Considering a matrix multiply kernel has approximatelly 2xNxMxK arithmetic operations\n",
    "\n",
    "And our selected kernel has the following sizes: \n",
    "\n",
    "```mlir\n",
    "linalg.batch_matmul ins(%A, %B : memref<1x4x8xf32>, memref<1x8x4xf32>) \n",
    "                    outs(%C : memref<1x4x4xf32>)\n",
    "\n",
    "```\n",
    "M=4, K=8, N=4\n",
    "\n",
    "We have approximatelly **256** floating point aritihmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giga_multiplier=1e9\n",
    "flop_count = 256 # arithmetic float point operations\n",
    "target_frequency = 200e+6 # 200MHz\n",
    "\n",
    "optimized_runtime_in_s = optimized_runtime/target_frequency\n",
    "baseline_runtime_in_s = baseline_runtime/target_frequency \n",
    "\n",
    "baseline_flops_per_watt= flop_count/baseline_runtime_in_s/baseline_total_power\n",
    "optimized_flops_per_watt= flop_count/optimized_runtime_in_s/optimized_total_power\n",
    "\n",
    "\n",
    "print(\"Execution in cycles of Baseline kernel:  {}\".format(baseline_runtime))\n",
    "print(\"Execution in cycles of Optimized kernel:   {}\".format(optimized_runtime))\n",
    "\n",
    "print(\"Speedup: \\t\\t\\t{:.2f}x\".format(baseline_runtime/optimized_runtime))\n",
    "print(\"Area utilization overhead: \\t {:.2f}x\".format(optimized_utilization_area/baseline_utilization_area))\n",
    "print(\"Area overhead: \\t\\t\\t {:.2f}x\".format(optimized_available_area/baseline_available_area))\n",
    "print(\"Power overhead: \\t\\t {:.2f}x\".format(optimized_total_power/baseline_total_power))\n",
    "\n",
    "print(\"Baseline  \\t\\t\\t {:.2f} GFLOPS/W \".format(baseline_flops_per_watt/giga_multiplier))\n",
    "print(\"Optimized \\t\\t\\t{:.2f} GFLOPS/W\".format(optimized_flops_per_watt/giga_multiplier))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated GDSII files\n",
    "\n",
    "Output files can be found here:\n",
    "\n",
    "* output/baseline/HLS_output/Synthesis/bash_flow/openroad/results/nangate45/main_kernel/base/6_final.gds\n",
    "* output/optimized/HLS_output/Synthesis/bash_flow/openroad/results/nangate45/main_kernel/base/6_final.gds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline and Optimized Side by Side\n",
    "\n",
    "![Side-By-Size](imgs/gds-side-by-side.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93c7c3955e7e5d34b1892eb3eed2f106b954557791a7d399a089a63ede089a6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
